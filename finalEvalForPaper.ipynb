{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Graph Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def wer(sentence1, sentence2):\n",
    "    from Levenshtein import distance as ld\n",
    "    sen1, sen2 = str(sentence1), str(sentence2)\n",
    "    norLen = max(len(sen1), len(sen2))\n",
    "    return ld(sen1,sen2)/norLen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_processed_wer(list_input):\n",
    "    import math\n",
    "    n = len(list_input)\n",
    "    print(\"n is \",n)\n",
    "    percentWer = []\n",
    "    for i in range(1,101):\n",
    "        till_num = math.ceil(0.01 * i * n)\n",
    "#         print(\"till_num is \",till_num,\" for i as \",i)\n",
    "#         print(\"i is \",i,\" till_num is \",till_num)\n",
    "        cum_sum = 0\n",
    "        for j in range(till_num):\n",
    "            cum_sum += list_input[j]\n",
    "        percentWer.append(cum_sum/till_num)\n",
    "    \n",
    "    return percentWer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cdf_wer_plot(appWer, ivrWer):\n",
    "    import matplotlib.pyplot as plt\n",
    "    import matplotlib.ticker as plticker\n",
    "    import numpy as np\n",
    "    nAudio = len(appWer)\n",
    "    fig, ax = plt.subplots()\n",
    "    ax.set_xlabel(\"Word Error Rate\")\n",
    "    ax.set_ylabel(\"Percentage of audio files(%)\")\n",
    "    \n",
    "    audio = np.arange(1,101)\n",
    "    \n",
    "#     appWer.sort()\n",
    "#     ivrWer.sort()\n",
    "    #Here is how cdf starts\n",
    "#     x=np.arange(1,nAudio)\n",
    "#     frequency=np.array([3,8,4,5,3,6])\n",
    "#     pdf=frequency/np.sum(frequency)\n",
    "#     cdf=np.cumsum(pdf)\n",
    "    #Here is how the cdf ends\n",
    "#     appWer.sort()\n",
    "#     ivrWer.sort()\n",
    "\n",
    "    \n",
    "    appWer.sort()\n",
    "    ivrWer.sort()\n",
    "    \n",
    "    appWerProcessed = calculate_processed_wer(appWer)\n",
    "    ivrWerProcessed = calculate_processed_wer(ivrWer)\n",
    "    \n",
    "#     appWerProcessed.sort()\n",
    "#     ivrWerProcessed.sort()\n",
    "    \n",
    "    appPdf = appWerProcessed/np.sum(appWerProcessed)\n",
    "    ivrPdf = ivrWerProcessed/np.sum(ivrWerProcessed)\n",
    "    \n",
    "    \n",
    "    appCdf = np.cumsum(appPdf)\n",
    "    ivrCdf = np.cumsum(ivrPdf)\n",
    "    \n",
    "    ax.plot(appCdf, audio, color = 'red', label = 'Through Application')\n",
    "    ax.plot(ivrCdf, audio, color = 'blue', label = 'Through IVR')\n",
    "    loc = plticker.MultipleLocator(base=0.1)\n",
    "    ax.xaxis.set_major_locator(loc)\n",
    "    ax.legend()\n",
    "    plt.savefig('Comparsion_cdf')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# App Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "appData = pd.read_excel('app_data.xlsx')\n",
    "q1 = appData[appData['Question']=='कृपया अपना नाम बताएं |']\n",
    "q2 = appData[appData['Question']=='आप कहाँ रहते हैं?']\n",
    "q3 = appData[appData['Question']=='आपके परिवार में कुल कितने लोग हैं?']\n",
    "q4 = appData[appData['Question']=='क्या आप या आपके परिवर में कोई महिला गर्भवती है?']\n",
    "q5 = appData[appData['Question']=='गर्भवती महिला का कौनसा महीना चल रहा है?']\n",
    "q6 = appData[appData['Question']=='सवास्थ्य कर्मी या डॉक्टर के अनुसार गर्भवती महिला की आनुमानिक डिलीवरी का महीना कौन सा है?']\n",
    "q7 = appData[appData['Question']=='आपके कितना बच्चे है? अपने जवाब में बच्चों की कुल संख्या बताएँ|']\n",
    "q8 = appData[appData['Question']=='सबसे छोटे बच्चे की उम्र कितनी है?']\n",
    "q9 = appData[appData['Question']=='बच्चे की जनम की तारीख क्या है?']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# appRemain = appData[ ( (appData['Question']!='कृपया अपना नाम बताएं |') \n",
    "#  & (appData['Question']!='आप कहाँ रहते हैं?') \n",
    "#  & (appData['Question']!='आपके परिवार में कुल कितने लोग हैं?')\n",
    "#  & (appData['Question']!='क्या आप या आपके परिवर में कोई महिला गर्भवती है?') \n",
    "#  & (appData['Question']!='गर्भवती महिला का कौनसा महीना चल रहा है?') \n",
    "#  & (appData['Question']!='सवास्थ्य कर्मी या डॉक्टर के अनुसार गर्भवती महिला की आनुमानिक डिलीवरी का महीना कौन सा है?') \n",
    "#  & (appData['Question']!='आपके कितना बच्चे है? अपने जवाब में बच्चों की कुल संख्या बताएँ|') \n",
    "#  & (appData['Question']!='सबसे छोटे बच्चे की उम्र कितनी है?')\n",
    "#  & (appData['Question']!='बच्चे की जनम की तारीख क्या है?'))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "sttAppData = pd.concat([q2['STT transcription'],q3['STT transcription'],q4['STT transcription'],q5['STT transcription'],q6['STT transcription'],q7['STT transcription'],q8['STT transcription'],q9['STT transcription']]).tolist()\n",
    "manualAppData = pd.concat([q2['Moderator transcription'],q3['Moderator transcription'],q4['Moderator transcription'],q5['Moderator transcription'],q6['Moderator transcription'],q7['Moderator transcription'],q8['Moderator transcription'],q9['Moderator transcription']]).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(173, 9)\n"
     ]
    }
   ],
   "source": [
    "print(appData.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "appWer = []\n",
    "for i in range(len(sttAppData)):\n",
    "    appWer.append(wer(sttAppData[i],manualAppData[i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IVR Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2656, 2)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "d1 = pd.read_excel('vb1.xlsx')\n",
    "d2 = pd.read_excel('vb2.xlsx')\n",
    "d3 = pd.read_excel('round3.xlsx')\n",
    "d4 = pd.read_excel('r4.xlsx')\n",
    "d1Temp = d1[['STT transcription','Moderator Transcription']]\n",
    "d2Temp = d2[['STT transcription','Moderator Transcription']]\n",
    "d3Temp = d3[['STT transcription','Moderator Transcription']]\n",
    "d4Temp = d4[['STT transcription','Moderator Transcription']]\n",
    "frames = [d1Temp, d2Temp, d3Temp, d4Temp]\n",
    "ivrData = pd.concat(frames)\n",
    "print(ivrData.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "sttIvrData = ivrData['STT transcription'].tolist()\n",
    "manualIvrData = ivrData['Moderator Transcription'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "ivrWer = []\n",
    "for i in range(len(sttIvrData)):\n",
    "    ivrWer.append(wer(sttIvrData[i],manualIvrData[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2656\n"
     ]
    }
   ],
   "source": [
    "print(len(ivrWer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n is  140\n",
      "n is  2656\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "cdf_wer_plot(appWer, ivrWer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preperation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "r4Data = pd.read_excel('r4.xlsx')\n",
    "r4Final = r4Data[r4Data['STT transcription'].notnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(614, 15)\n",
      "(365, 15)\n"
     ]
    }
   ],
   "source": [
    "print(r4Data.shape)\n",
    "print(r4Final.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "childR4 = r4Final[r4Final['Question']=='Aapke kitne bachche hai Aapna jawab mein bachchon ki kul sankhya bataye?']\n",
    "familyR4 = r4Final[r4Final['Question']=='Aapke parivar mein kul kitne log rehte hain?']\n",
    "pregWomanR4 = r4Final[r4Final['Question']=='Garbhvati  mahila ka kaunsa mahina chal raha hai?']\n",
    "dobRound4 = r4Final[r4Final['Question']=='Bachche ki janam ki tarikh kya hai']\n",
    "haaNaR4 = r4Final[r4Final['Question']=='Kya aap ya aapke parivar me koi mahila garbhvati hai?']\n",
    "umraR4 = r4Final[r4Final['Question']=='Sabse chote bacche ki umar kitni hai']\n",
    "\n",
    "noOfChildrenR4 = childR4[['Question','Ground truth entity','DF entity','STT transcription','Moderator Transcription']]\n",
    "totalFamilyR4 = familyR4[['Question','Ground truth entity','DF entity','STT transcription','Moderator Transcription']]\n",
    "monthsPregnantR4 = pregWomanR4[['Question','Ground truth entity','DF entity','STT transcription','Moderator Transcription']]\n",
    "dobR4 = dobRound4[['Question','Ground truth entity','DF entity','STT transcription','Moderator Transcription']]\n",
    "yesNoR4 = haaNaR4[['Question','Ground truth entity','DF entity','STT transcription','Moderator Transcription']]\n",
    "ageR4 = umraR4[['Question','Ground truth entity','DF entity','STT transcription','Moderator Transcription']]\n",
    "\n",
    "# totalFamilyR4.to_excel('totalFamilyR4.xlsx')\n",
    "# noOfChildrenR4.to_excel('noOfChildrenR4.xlsx')\n",
    "# monthsPregnantR4.to_excel('monthsPregnantR4.xlsx')\n",
    "# dobR4.to_excel('dobR4.xlsx')\n",
    "# yesNoR4.to_excel('yesNoR4.xlsx')\n",
    "# ageR4.to_excel('ageR4.xlsx')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Date of Birth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "dobR12 = pd.read_excel('dobTrain.xlsx')\n",
    "dobR12 = dobR12[['Question','Ground truth entity','DF entity','STT transcription','Moderator Transcription','Quality']]\n",
    "dobR3 = pd.read_excel('dobRound3.xlsx')\n",
    "dobR3 = dobR3[['Question','Ground truth entity','DF entity','STT transcription','Moderator Transcription','Quality']]\n",
    "dobR4 = pd.read_excel('dobR4.xlsx')\n",
    "dobR4 = dobR4[['Question','Ground truth entity','DF entity','STT transcription','Moderator Transcription','Quality']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(112, 6) (131, 6) (28, 6)\n"
     ]
    }
   ],
   "source": [
    "print(dobR12.shape, dobR3.shape, dobR4.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "def near_str(word1, word2):\n",
    "    import textdistance as td\n",
    "    word1 = str(word1)\n",
    "    word2 = str(word2)\n",
    "    return td.levenshtein.normalized_similarity(word1, word2)\n",
    "\n",
    "def checkInSen(word, sentence):\n",
    "    word = str(word)\n",
    "    sentence = str(sentence)\n",
    "    for pos_words in sentence.split():\n",
    "        if near_str(word, pos_words) >= 0.65:\n",
    "            return True\n",
    "    return False\n",
    "\n",
    "def findDate(sentence):\n",
    "    sentence = str(sentence)\n",
    "    import json\n",
    "    outSentence = {'Date':'-1','Month':'-1','Year':'-1'}\n",
    "\n",
    "    rawMonths=['जनवरी','फरवरी','मार्च','अप्रैल','मई','जून','जुलाई','अगस्त','सितंबर','अक्टूबर','नवंबर','दिसंबर']\n",
    "    rawMonthsDict = {i:j%12+1 for (j,i) in enumerate(rawMonths)}\n",
    "    hindiMonths=['चैत्र','बैसाख','ज्येष्ठ','आषाढ़','सावन','भाद्रपद','आश्विन','कार्तिक','अग्रहायण','पौष','माघ','फाल्गुन']\n",
    "    hindiMonthsDict = {i:((j+3)%12+1) for (j,i) in enumerate(hindiMonths)}\n",
    "    hindiMonthPrefix=['पहला','दूसरा','तीसरा','चौथा','पांचवां','छठा','सातवां','आठवां','नौवां','दसवां','ग्यारहवां','बारहवां']\n",
    "    hindiMonthPrefixDict = {i:j%12+1 for (j,i) in enumerate(hindiMonthPrefix)}\n",
    "\n",
    "    #Now for date and month\n",
    "    flag=0\n",
    "    for month in rawMonths:\n",
    "        if month in sentence:\n",
    "            outSentence['Month']=str(rawMonthsDict[month])\n",
    "            flag=1\n",
    "            break\n",
    "            \n",
    "\n",
    "    #Now checking for months in hindi\n",
    "    if flag==0:\n",
    "        for month in hindiMonths:\n",
    "            if month in sentence:\n",
    "                outSentence['Month']=str(hindiMonthsDict[month]) \n",
    "                flag=1\n",
    "                break\n",
    "    \n",
    "    \n",
    "    \n",
    "    item=sentence.replace(\"-\",\" \").replace(\"/\",\" \").split()\n",
    "    \n",
    "    for i in range(len(item)):\n",
    "        item[i]= item[i].lstrip('0')\n",
    "    \n",
    "    # Near string matching for rawMonths\n",
    "    \n",
    "    if flag==0:\n",
    "        for senWords in item:\n",
    "            for month in rawMonths:\n",
    "                if near_str(senWords,month) >= 0.65:\n",
    "                    outSentence['Month'] = str(rawMonthsDict[month])\n",
    "                    flag = 1\n",
    "                    break\n",
    "            \n",
    "            if flag==1:\n",
    "                break\n",
    "    \n",
    "    # Near String Matching for hindiMonths\n",
    "    if flag==0:\n",
    "        for senWords in item:\n",
    "            for month in hindiMonths:\n",
    "                if near_str(senWords, month) >= 0.65:\n",
    "                    outSentence['Month'] = str(hindiMonthsDict[month])\n",
    "                    flag = 1\n",
    "                    break\n",
    "            \n",
    "            if flag==1:\n",
    "                break\n",
    "        \n",
    "\n",
    "    # Now for hindi prefix like pehla mahina, dusra mahine, teesra mahina and continued till 12th months\n",
    "\n",
    "    if(len(item)>=2):\n",
    "        for i in range(len(item)-1):\n",
    "            if checkInSen(item[i], hindiMonthPrefix) and (near_str(item[i+1],'महीना') >= 0.65 or near_str(item[i+1],'महिना')\n",
    "                                                >= 0.65):\n",
    "                if flag==0:\n",
    "                    outSentence['Month'] =  hindiMonthPrefixDict[item[i]] #item[i]\n",
    "                    flag=1\n",
    "                    break\n",
    "\n",
    "#     total+=len(item)\n",
    "    \n",
    "    \n",
    "    \n",
    "    #For Months\n",
    "    if(len(item)>=2):\n",
    "        for i in range(len(item)-1):\n",
    "                if item[i].isdigit() and item[i+1].isdigit() and len(item[i])!=4 and len(item[i+1])!=4:\n",
    "                    if flag==0:\n",
    "                        if (int(item[i+1])) <= 12:\n",
    "                            outSentence['Month'] =  str(int(item[i+1])) #item[i+1]\n",
    "                            flag=1\n",
    "                            break\n",
    "                elif item[i].isdigit() and item[i+1].isdigit() and len(item[i])!=4 and len(item[i+1])==4:\n",
    "                    if flag==0:\n",
    "                        if len(item[i])==1 and int(item[i])!=0:\n",
    "                            outSentence['Month'] = str(int(item[i])) #item[i]\n",
    "                            flag=1\n",
    "                            break\n",
    "                        elif len(item[i])==3:\n",
    "                            if int(item[i][:2]) <= 31 and int(item[i][2]) != 0:\n",
    "                                outSentence['Month'] =  str(int(item[i][2])) #item[i][2]\n",
    "                                flag = 1\n",
    "                                break\n",
    "                            elif int(item[i][:2]) <= 31 and int(item[i][2]) == 0:\n",
    "                                if int(item[i][1])==1:\n",
    "                                    outSentence['Month'] =  str(int(item[i][1:])) #item[i][1:]\n",
    "                                    flag = 1\n",
    "                                    break\n",
    "                        elif len(item[i])==2:\n",
    "                            if int(item[i])<=12:\n",
    "                                outSentence['Month'] =  str(int(item[i])) #item[i]\n",
    "                                flag=1\n",
    "                                break\n",
    "                            else:\n",
    "                                outSentence['Month'] =  str(int(item[i][1])) #item[i][1]\n",
    "                                flag = 1\n",
    "                                break\n",
    "                        else:\n",
    "                            z = 2 #dummy\n",
    "\n",
    "                elif item[i].isdigit() and item[i+1].isdigit() and len(item[i])==4 and len(item[i+1])==4:\n",
    "                    if flag==0:\n",
    "                        if int(item[i+1]) <= 2100 and int(item[i+1]) >= 1900:\n",
    "                            if int(item[i][2:]) <= 12:\n",
    "                                outSentence['Month'] =  str(int(item[i][2:])) #item[i][2:]\n",
    "                                flag = 1\n",
    "                                break\n",
    "                else:\n",
    "                    z=2 #Dummy\n",
    "\n",
    "#     if truthMonths[-1]==1:\n",
    "#         trainMonthOut.append(1)\n",
    "#     else:\n",
    "#         trainMonthOut.append(0)\n",
    "\n",
    "    flagDate=0\n",
    "    if len(item)>=2:\n",
    "        for i in range(len(item)-1):\n",
    "                if item[i].isdigit() and item[i+1].isdigit() and len(item[i])!=4 and len(item[i+1])!=4:\n",
    "                    if flagDate==0:\n",
    "                        outSentence['Date'] = item[i]\n",
    "                        flagDate=1\n",
    "                        break\n",
    "                elif item[i].isdigit() and len(item[i])!=4 and not item[i+1].isdigit() and int(item[i])<32:\n",
    "                    if flagDate==0:\n",
    "                        suppList = [\"साल\",\"महीना\",\"महिना\"]\n",
    "                        if not(item[i+1] in suppList):\n",
    "                            outSentence['Date'] = item[i]\n",
    "                            flagDate=1\n",
    "                            break\n",
    "                elif item[i].isdigit() and item[i+1].isdigit() and len(item[i])!=4 and len(item[i+1])==4:\n",
    "                    if flagDate==0:\n",
    "                        if len(item[i])==3:\n",
    "                            if int(item[i][:2]) <= 31 and int(item[i][2]) != 0:\n",
    "                                outSentence['Date'] = item[i][:2]\n",
    "                                flagDate = 1\n",
    "                                break\n",
    "                            elif int(item[i][:2]) <= 31 and int(item[i][2]) == 0:\n",
    "                                if int(item[i][1])==1:\n",
    "                                    outSentence['Date'] = item[i][0]\n",
    "                                    flagDate = 1\n",
    "                                    break\n",
    "                        elif len(item[i])==2:\n",
    "                            if int(item[i])<=12:\n",
    "                                z = 2 #Do  nothing\n",
    "                            else:\n",
    "                                outSentence['Date'] = item[i][0]\n",
    "                                flagDate = 1\n",
    "                                break\n",
    "                        else:\n",
    "                            z = 2 #dummy\n",
    "                elif item[i].isdigit() and item[i+1].isdigit() and len(item[i])==4 and len(item[i+1])==4:\n",
    "                    if flagDate==0:\n",
    "                        if int(item[i+1]) <= 2100 and int(item[i+1]) >= 1900:\n",
    "                            if int(item[i][2:]) <= 12:\n",
    "                                outSentence['Date'] = item[i][:2]\n",
    "                                flagDate = 1\n",
    "                                break\n",
    "                else:\n",
    "                    z=2\n",
    "    elif len(item) == 1:\n",
    "        try:\n",
    "            if type(int(item[0]))==int:\n",
    "                if int(item[0]) <= 31:\n",
    "                    outSentence['Date'] = item[0]\n",
    "                    flagDate = 1\n",
    "        except:\n",
    "            z = 2 # Basically do nothing\n",
    "\n",
    "    ##############################################################################################\n",
    "    flagYear=0\n",
    "    for items in sentence.replace(\"-\",\" \").split():\n",
    "        try:\n",
    "            if len(items) == 4 and int(items) > 1900 and int(items) < 2100:\n",
    "                outSentence['Year'] = items\n",
    "                flagYear=1\n",
    "                break\n",
    "        except:\n",
    "            z=2 #Dummy z\n",
    "    if flagYear!=1:\n",
    "        words = sentence.replace(\"-\",\" \").split()\n",
    "        for i in range(len(words)-2):\n",
    "            try:\n",
    "                if (type(int(words[i])) == int)  and (type(int(words[i+1]))==int) and (type(int(words[i+2]))==int):\n",
    "                    if len(words[i+2])==2:\n",
    "                        if int(words[i+2]) > 50:\n",
    "                            outSentence['Year'] = \"19\"+words[i+2]\n",
    "                        else:\n",
    "                            outSentence['Year'] = \"20\"+words[i+2]\n",
    "                        flagYear = 1\n",
    "                        break\n",
    "            except:\n",
    "                z=2\n",
    "    if flagYear!=1:\n",
    "        words = sentence.replace(\"-\",\" \").split()\n",
    "        for i in range(len(words)-1):\n",
    "            if words[i] in rawMonths or words[i] in hindiMonths or words[i] in hindiMonthPrefix:\n",
    "                if words[i+1].isdigit() and len(words[i+1])==2:\n",
    "                    if int(words[i+1])>=50:\n",
    "                        outSentence['Year'] = \"19\"+str(words[i+1])\n",
    "                    else:\n",
    "                        outSentence['Year'] = \"20\"+str(words[i+1])\n",
    "                    flagYear =1\n",
    "                    break\n",
    "\n",
    "#     json_Output = json.dumps(outSentence,ensure_ascii=False)\n",
    "    return outSentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(112, 6) (131, 6) (28, 6)\n"
     ]
    }
   ],
   "source": [
    "print(dobR12.shape, dobR3.shape, dobR4.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(271, 6)\n",
      "(198, 6)\n"
     ]
    }
   ],
   "source": [
    "dobData = pd.concat([dobR12, dobR3, dobR4])\n",
    "print(dobData.shape)\n",
    "dobData = dobData[dobData['Quality']==1]\n",
    "print(dobData.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Yaha Apne Module ka\n",
    "import datetime\n",
    "dateOut, monthOut, yearOut = [], [], []\n",
    "\n",
    "\n",
    "for text in dobData['STT transcription']:\n",
    "    if type(text)==datetime.datetime:\n",
    "        tempDate = datetime.datetime.date(text)\n",
    "        text = tempDate.strftime(\"%d-%m-%Y\")\n",
    "    \n",
    "    out = findDate(text)\n",
    "    dateOut.append(out['Date'])\n",
    "    monthOut.append(out['Month'])\n",
    "    yearOut.append(out['Year'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "dobAct = dobData['Ground truth entity'].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(dobAct)\n",
    "import datetime\n",
    "for i in range(len(dobAct)):\n",
    "    if type(dobAct[i])==datetime.datetime:\n",
    "        dobAct[i] = dobAct[i].strftime('%d/%m/%Y')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "dateAct , monthAct , yearAct = [], [], []\n",
    "for item in dobAct:\n",
    "    item = str(item)\n",
    "    l = item.split('/')\n",
    "    if len(l)==1:\n",
    "        dateAct.append(str(-1))\n",
    "        monthAct.append(str(-1))\n",
    "        yearAct.append(str(-1))\n",
    "    elif len(l)==2:\n",
    "        dateAct.append(str(-1))\n",
    "        monthAct.append(str(int(l[0])))\n",
    "        yearAct.append(str(int(l[1])))\n",
    "    else:\n",
    "        dateAct.append(str(int(l[0])))\n",
    "        monthAct.append(str(int(l[1])))\n",
    "        yearAct.append(str(int(l[2])))\n",
    "# print(dateAct)\n",
    "# print(monthAct)\n",
    "# print(yearAct)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Date Accuracy is  0.9595959595959596\n",
      "Month Accuracy is  0.8787878787878788\n",
      "Year Accuracy is  0.9242424242424242\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "print(\"Date Accuracy is \", accuracy_score(dateAct, dateOut))\n",
    "print(\"Month Accuracy is \", accuracy_score(monthAct, monthOut))\n",
    "print(\"Year Accuracy is \", accuracy_score(yearAct, yearOut))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "l1DateAct = [0 if item=='-1' else 1 for item in dateAct]\n",
    "l1MonthAct = [0 if item=='-1' else 1 for item in monthAct]\n",
    "l1YearAct = [0 if item=='-1' else 1 for item in yearAct]\n",
    "\n",
    "l1DateOut = [0 if item=='-1' else 1 for item in dateOut]\n",
    "l1MonthOut = [0 if item=='-1' else 1 for item in monthOut]\n",
    "l1YearOut = [0 if item=='-1' else 1 for item in yearOut]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_score, f1_score, recall_score, accuracy_score, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "0.9947643979057591\n",
      "0.9895833333333334\n",
      "0.98989898989899\n"
     ]
    }
   ],
   "source": [
    "print(precision_score(l1DateAct,l1DateOut))\n",
    "print(f1_score(l1DateAct, l1DateOut))\n",
    "print(recall_score(l1DateAct, l1DateOut))\n",
    "print(accuracy_score(l1DateAct, l1DateOut))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9943181818181818\n",
      "0.9536784741144414\n",
      "0.9162303664921466\n",
      "0.9141414141414141\n"
     ]
    }
   ],
   "source": [
    "print(precision_score(l1MonthAct,l1MonthOut))\n",
    "print(f1_score(l1MonthAct, l1MonthOut))\n",
    "print(recall_score(l1MonthAct, l1MonthOut))\n",
    "print(accuracy_score(l1MonthAct, l1MonthOut))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.994413407821229\n",
      "0.9700272479564034\n",
      "0.9468085106382979\n",
      "0.9444444444444444\n"
     ]
    }
   ],
   "source": [
    "print(precision_score(l1YearAct,l1YearOut))\n",
    "print(f1_score(l1YearAct, l1YearOut))\n",
    "print(recall_score(l1YearAct, l1YearOut))\n",
    "print(accuracy_score(l1YearAct, l1YearOut))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  6   0]\n",
      " [  2 190]]\n",
      "[[  6   1]\n",
      " [ 16 175]]\n",
      "[[  9   1]\n",
      " [ 10 178]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "print(confusion_matrix(l1DateAct, l1DateOut))\n",
    "print(confusion_matrix(l1MonthAct, l1MonthOut))\n",
    "print(confusion_matrix(l1YearAct, l1YearOut))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> Dialogflow for DateOfBirth </b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Yahan DialogFlow ka for round 1 & 2\n",
    "import json\n",
    "dobR12 = dobR12[dobR12['Quality']==1]\n",
    "dobDF = dobR12['DF entity'].tolist()\n",
    "dobDialogFlow = []\n",
    "for pred in dobDF:\n",
    "        try:\n",
    "            ent = json.loads(pred)\n",
    "            dobDialogFlow.append(str(list(ent['entity'][0].values())[0]))\n",
    "        except:\n",
    "            dobDialogFlow.append(\"#\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "dateDFOut, monthDFOut, yearDFOut = [], [], []\n",
    "for sentence in dobDialogFlow:\n",
    "    sentence = sentence.replace('/','-')\n",
    "#     print(sentence)\n",
    "    if sentence=='#':\n",
    "        dateDFOut.append(-1)\n",
    "        monthDFOut.append(-1)\n",
    "        yearDFOut.append(-1)\n",
    "    else:\n",
    "        here = sentence.split('-')\n",
    "        dateDFOut.append(str(int(here[2])))\n",
    "        monthDFOut.append(str(int(here[1])))\n",
    "        yearDFOut.append(str(int(here[0])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "90\n",
      "90\n",
      "90\n"
     ]
    }
   ],
   "source": [
    "print(len(dateDFOut))\n",
    "print(len(monthDFOut))\n",
    "print(len(yearDFOut))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Yahan dialogflow ka for round3 and round4\n",
    "dobR3 = dobR3[dobR3['Quality']==1]\n",
    "dobR4 = dobR4[dobR4['Quality']==1]\n",
    "\n",
    "dobDF = pd.concat([dobR3['DF entity'],dobR4['DF entity']]).tolist()\n",
    "import datetime\n",
    "for i in range(len(dobDF)):\n",
    "    if type(dobDF[i])==datetime.datetime:\n",
    "        dobDF[i] = dobDF[i].strftime('%m/%d/%Y')\n",
    "        \n",
    "\n",
    "for sentence in dobDF:\n",
    "    sentence = str(sentence)\n",
    "    sentence = sentence.replace('/','-')\n",
    "\n",
    "    if sentence=='NOENTITY' or sentence=='nan':\n",
    "#         print('aaya kya')\n",
    "        dateDFOut.append(str(-1))\n",
    "        monthDFOut.append(str(-1))\n",
    "        yearDFOut.append(str(-1))\n",
    "    else:\n",
    "        here = sentence.split('-')\n",
    "        if len(here)==1:\n",
    "            dateDFOut.append(str(here[0]))\n",
    "            monthDFOut.append(str(-1))\n",
    "            yearDFOut.append(str(-1))\n",
    "        else:\n",
    "            dateDFOut.append(str(int(here[1])))\n",
    "            monthDFOut.append(str(int(here[0])))\n",
    "            yearDFOut.append(str(int(here[2])))\n",
    "            \n",
    "# print(che)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replacing 5555 with -1 as 5555 was placed in place of -1 for dialogflow\n",
    "for i in range(len(dateDFOut)):\n",
    "    if dateDFOut[i]=='5555':\n",
    "        dateDFOut[i]='-1'\n",
    "    if monthDFOut[i]=='5555' :\n",
    "        monthDFOut[i] = '-1'\n",
    "    if yearDFOut[i]=='5555':\n",
    "        yearDFOut[i] = '-1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Date Accuracy for dialogflow is  0.7828282828282829\n",
      "Month Accuracy for dialogflow is  0.7777777777777778\n",
      "Year Accuracy for dialogflow is  0.7222222222222222\n"
     ]
    }
   ],
   "source": [
    "print(\"Date Accuracy for dialogflow is \",accuracy_score(dateAct, dateDFOut))\n",
    "print(\"Month Accuracy for dialogflow is \",accuracy_score(monthAct, monthDFOut))\n",
    "print(\"Year Accuracy for dialogflow is \", accuracy_score(yearAct, yearDFOut))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "l1DFDateOut = [0 if item=='-1' else 1 for item in dateDFOut]\n",
    "l1DFMonthOut = [0 if item=='-1' else 1 for item in monthDFOut]\n",
    "l1DFYearOut = [0 if item=='-1' else 1 for item in yearDFOut]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9651162790697675\n",
      "0.9120879120879122\n",
      "0.8645833333333334\n",
      "0.8383838383838383\n"
     ]
    }
   ],
   "source": [
    "print(precision_score(l1DateAct,l1DFDateOut))\n",
    "print(f1_score(l1DateAct, l1DFDateOut))\n",
    "print(recall_score(l1DateAct, l1DFDateOut))\n",
    "print(accuracy_score(l1DateAct, l1DFDateOut))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9593023255813954\n",
      "0.9090909090909092\n",
      "0.8638743455497382\n",
      "0.8333333333333334\n"
     ]
    }
   ],
   "source": [
    "print(precision_score(l1MonthAct,l1DFMonthOut))\n",
    "print(f1_score(l1MonthAct, l1DFMonthOut))\n",
    "print(recall_score(l1MonthAct, l1DFMonthOut))\n",
    "print(accuracy_score(l1MonthAct, l1DFMonthOut))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9479768786127167\n",
      "0.9085872576177285\n",
      "0.8723404255319149\n",
      "0.8333333333333334\n"
     ]
    }
   ],
   "source": [
    "print(precision_score(l1YearAct,l1DFYearOut))\n",
    "print(f1_score(l1YearAct, l1DFYearOut))\n",
    "print(recall_score(l1YearAct, l1DFYearOut))\n",
    "print(accuracy_score(l1YearAct, l1DFYearOut))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  0   6]\n",
      " [ 26 166]]\n",
      "[[  0   7]\n",
      " [ 26 165]]\n",
      "[[  1   9]\n",
      " [ 24 164]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "print(confusion_matrix(l1DateAct, l1DFDateOut))\n",
    "print(confusion_matrix(l1MonthAct, l1DFMonthOut))\n",
    "print(confusion_matrix(l1YearAct, l1DFYearOut))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install stanza\n",
    "import stanza\n",
    "# stanza.download('hi')\n",
    "hi_nlp = stanza.Pipeline('hi', processors='tokenize,lemma,pos,depparse', verbose=False, use_gpu=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import textdistance as td\n",
    "import difflib\n",
    "\n",
    "def findAge(sentence):\n",
    "#     print(sentence)\n",
    "    thresh = 0.65\n",
    "    sentence.replace(',',' ')\n",
    "    sentence.replace(':',' ')\n",
    "    sentence.replace('.',' ')\n",
    "    sentence.replace('_',' ')\n",
    "    sentence = sentence.strip()\n",
    "#     print('sentence baad me hua ',sentence)\n",
    "    age = -1\n",
    "    confd = 1\n",
    "    hindiNum = ['जीरो','एक' ,'दो' ,'तीन' ,'चार' ,'पांच' ,'छः' ,'सात'   ,'आठ' ,'नौ' ,'दस' , 'ग्यारह' ,'बारह','तेरह','चौदह',\n",
    " 'पंद्रह','सोलह','सत्रह','अट्ठारह' ,'उन्निस' ,'बीस','इक्कीस','बाईस','तेईस','चौबीस' ,'पच्चीस' ,'छब्बीस','सत्ताईस','अट्ठाईस' ,'उनतीस','तीस' ,'इकतीस' ,\n",
    " 'बत्तीस','तैंतीस','चौंतीस' ,'पैंतीस','छ्त्तीस' ,'सैंतीस','अड़तीस' ,'उनतालीस' ,'चालीस' ,'इकतालीस' ,'बयालीस','तैंतालीस','चौंतालीस' ,\n",
    " 'पैंतालीस' ,'छियालीस' ,'सैंतालीस','अड़तालीस','उनचास', 'पचास','इक्याबन' ,'बावन','तिरेपन','चौबन','पचपन', 'छप्पन','सत्तावन',\n",
    "'अट्ठावन','उनसठ','साठ','इकसठ','बासठ','तिरसठ','चौंसठ','पैंसठ','छियासठ' ,'सड़सठ','अड़सठ','उनहत्तर','सत्तर' ,'इकहत्तर' ,\n",
    "'बहत्तर','तिहत्तर','चौहत्तर' ,'पचहत्तर','छिहत्तर' ,'सतहत्तर' ,'अठहत्तर' ,'उनासी' ,'अस्सी' ,'इक्यासी' ,'बयासी','तिरासी' ,'चौरासी' ,\n",
    " 'पचासी' ,'छियासी' ,'सतासी' ,'अठासी' ,'नवासी' ,'नब्बे' ,'इक्यानबे' ,'बानवे' ,'तिरानवे' ,'चौरानवे' ,'पचानवे' ,'छियानवे' ,'सत्तानवे' ,\n",
    " 'अट्ठानवे' ,'निन्यानवे' ,'सौ']\n",
    "    \n",
    "    dictHindi = dict()\n",
    "    \n",
    "    # Just assigning numeral values to the hindi letters\n",
    "    count = 0\n",
    "    for word in hindiNum:\n",
    "        dictHindi[word] = count\n",
    "        count += 1\n",
    "    \n",
    "    dictHindi['छे'] = 6\n",
    "    \n",
    "    for words in sentence.split():\n",
    "#         print('words kya aaya isme ', words)\n",
    "        if age!=-1:\n",
    "            break\n",
    "        try:\n",
    "            if(type(int(words))==int):\n",
    "#                 print('isme aaya kya')\n",
    "                if(int(words) >= 0 and int(words) <= 1000):\n",
    "                    age = int(words)\n",
    "#                     print('age kya hua finally ',age)\n",
    "        except:\n",
    "            z = 2\n",
    "            \n",
    "    suffix = ['वी','टी','वा']\n",
    "    \n",
    "    if age==-1:\n",
    "        words = sentence.split()\n",
    "        for word in words:\n",
    "            for pos_word in hindiNum:\n",
    "                first = td.levenshtein.normalized_similarity(pos_word, word)\n",
    "                second = td.levenshtein.normalized_similarity(pos_word+suffix[0], word)\n",
    "                third = td.levenshtein.normalized_similarity(pos_word+suffix[1], word)\n",
    "                fourth = td.levenshtein.normalized_similarity(pos_word+suffix[2], word)\n",
    "                confd = max(confd, first, second, third, fourth)\n",
    "                if first >= thresh:\n",
    "                    return (dictHindi[pos_word],first)\n",
    "                elif second >= thresh or third >= thresh or fourth >= thresh:\n",
    "                    return (dictHindi[pos_word],max(second, third, fourth))\n",
    "                \n",
    "        \n",
    "        for word in words:\n",
    "            if word=='छे':\n",
    "                return (6,1)\n",
    "    \n",
    "    return age,confd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "def posTagging(sentence):\n",
    "    hi_doc = hi_nlp(sentence)\n",
    "    for sent in hi_doc.sentences:\n",
    "        out = []\n",
    "        for word in sent.words:\n",
    "            if word.pos=='NUM':\n",
    "               out.append(word.text) \n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "def checkZero(sentence):\n",
    "    import re\n",
    "    import textdistance as td\n",
    "    import difflib\n",
    "    thresh = 0.65\n",
    "    noList = [ 'नहीं' , 'ना', 'नाही']\n",
    "    words = sentence.split()\n",
    "    for word in words:\n",
    "        if word in noList:\n",
    "            return 1\n",
    "        else:\n",
    "            for pos_word in noList:\n",
    "                if td.levenshtein.normalized_similarity(pos_word, word) >= thresh:\n",
    "                    return 1\n",
    "    return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "def findNumeralData(sentence):\n",
    "    cZero = checkZero(sentence)\n",
    "    if cZero==1:\n",
    "        return (0,1)\n",
    "    out = posTagging(sentence)\n",
    "#     print(out)|\n",
    "    x = len(out)\n",
    "#     print(x)\n",
    "    if x == 0:\n",
    "#         print(out)\n",
    "        return findAge(sentence)\n",
    "    else:\n",
    "        res = -1\n",
    "        confd = 1\n",
    "        for agla in out:\n",
    "#             print(agla)\n",
    "            res,confd = findAge(agla)\n",
    "            if res!=-1:\n",
    "                break\n",
    "    return res,confd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This code is for months pregnant with slight modification\n",
    "import re\n",
    "import textdistance as td\n",
    "import difflib\n",
    "\n",
    "thresh = 0.65\n",
    "\n",
    "possible_words = {'शून्य':0,'एक':1,'दो':2,'तीन':3,'चार':4,'पांच':5,'छः':6,'सात':7,'आठ':8,'नौ':9,'लास्ट':9,'पहला':1,\n",
    "                  'दूसरा':2,'तीसरा':3,'चौथा':4,'पांचवा':5,'छत्ता':6,'चट्टा':6,'सातवा':7,'आठवा':8,'नौंवा':9,'नवा':9,'शुरू':1,\n",
    "                  'नाना':9}\n",
    "suffix = ['वी','टी','वा']\n",
    "general_words = {'हां':1,'हाँ':1,'सब':9,'नहीं':0,'ना':0}\n",
    "\n",
    "def get_digits(word):\n",
    "    if not re.search('\\d+', word):\n",
    "        # no digits from 0-9\n",
    "        if not re.search('[०१२३४५६७८९]+', word):\n",
    "            return -1\n",
    "        return re.search('[०१२३४५६७८९]+', word).group()\n",
    "    return re.search('\\d+', word).group()\n",
    "\n",
    "def get_month(sent):    # Similar to get education\n",
    "    sent = str(sent)\n",
    "    sent = sent.strip()\n",
    "    words = sent.split()\n",
    "    for word in words:\n",
    "        digits = get_digits(word)\n",
    "        if digits != -1:\n",
    "            return int(digits)\n",
    "        for pos_word in possible_words:\n",
    "            if td.levenshtein.normalized_similarity(pos_word, word) >= thresh:\n",
    "                return possible_words[pos_word]\n",
    "            elif td.levenshtein.normalized_similarity(pos_word+suffix[0], word) >= thresh\\\n",
    "             or td.levenshtein.normalized_similarity(pos_word+suffix[1], word) >= thresh\\\n",
    "             or td.levenshtein.normalized_similarity(pos_word+suffix[2], word) >= thresh:\n",
    "                return possible_words[pos_word]\n",
    "        for gen_word in general_words:\n",
    "            if gen_word == word:    # It is better to have exact match here\n",
    "#                 print(word, gen_word)\n",
    "                return general_words[gen_word]\n",
    "    return -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(27, 7) (17, 7) (18, 7)\n"
     ]
    }
   ],
   "source": [
    "# mp stands for month pregnant\n",
    "\n",
    "mp12 = pd.read_excel('monthsPregnantR12.xlsx')\n",
    "mp3 = pd.read_excel('monthsPregnantR3.xlsx')\n",
    "mp4 = pd.read_excel('monthsPregnantR4.xlsx')\n",
    "\n",
    "print(mp12.shape, mp3.shape, mp4.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(62, 7)\n"
     ]
    }
   ],
   "source": [
    "monthsPregnant = pd.concat([mp12, mp3, mp4])\n",
    "print(monthsPregnant.shape)\n",
    "# monthsPregnant = monthsPregnant[monthsPregnant['Quality']==1]\n",
    "# print(monthsPregnant.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "months_pregnant_out = []\n",
    "for text in monthsPregnant['STT transcription']:\n",
    "    text = str(text)\n",
    "    a = get_month(text)\n",
    "    months_pregnant_out.append(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "months_pregnant_gt = monthsPregnant['Ground truth entity']\n",
    "months_pregnant_act = []\n",
    "\n",
    "for item in months_pregnant_gt:\n",
    "    try:\n",
    "        if (type(int(item)) == int):\n",
    "            months_pregnant_act.append(int(item))\n",
    "    except:\n",
    "            months_pregnant_act.append(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "months_pregnant_df = monthsPregnant['DF entity']\n",
    "months_pregnant_dfOut = []\n",
    "for item in months_pregnant_df:\n",
    "    try:\n",
    "        if (type(int(item)) == int):\n",
    "            months_pregnant_dfOut.append(int(item))\n",
    "    except:\n",
    "            months_pregnant_dfOut.append(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "62 62 62\n"
     ]
    }
   ],
   "source": [
    "print(len(months_pregnant_out), len(months_pregnant_act), len(months_pregnant_dfOut))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "l1Act, l2Act = [], []\n",
    "for item in months_pregnant_gt:\n",
    "    try:\n",
    "        if (type(int(item)) == int):\n",
    "            l1Act.append(1)\n",
    "            l2Act.append(int(item))\n",
    "    except:\n",
    "            l1Act.append(0)\n",
    "            l2Act.append(-1)\n",
    "\n",
    "l1Out = []\n",
    "for item in months_pregnant_out:\n",
    "    if item==-1:\n",
    "        l1Out.append(0)\n",
    "    else:\n",
    "        l1Out.append(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "l1Out = []\n",
    "for item in months_pregnant_dfOut:\n",
    "    if item==-1:\n",
    "        l1Out.append(0)\n",
    "    else:\n",
    "        l1Out.append(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "0.8750000000000001\n",
      "0.7777777777777778\n",
      "Presence Identification accuracy is  0.8064516129032258\n",
      "Correctness accuracy is  0.8225806451612904\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, f1_score, recall_score, confusion_matrix\n",
    "print(precision_score(l1Act,l1Out))\n",
    "print(f1_score(l1Act,l1Out))\n",
    "print(recall_score(l1Act, l1Out))\n",
    "print(\"Presence Identification accuracy is \",accuracy_score(l1Act, l1Out))\n",
    "print(\"Correctness accuracy is \",accuracy_score(l2Act,months_pregnant_out))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 8  0]\n",
      " [12 42]]\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(l1Act, l1Out))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Error Analysis </b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15\n",
      "['लास्ट महीना' 'नवा महीना चल रहा है' 'नाना' 'छठा महीना' 'दूसरा महीना'\n",
      " 'छठा महीना चल रहे हैं' 'दूसरा महीना चल रहा है' 'नवा महीना' 'दूसरा महीना'\n",
      " 'नहीं गर्भवती महिला नहीं है मेरे पास' 'तीसरा' 'तीसरा'\n",
      " '9 महीना हो ना हो तनी' 'छठा महीना' 'मेरा घर में कोई नहीं है वैसा']\n",
      "[ 9  9  9  6  2  6  2  9  2 -1  3  3  9  6 -1]\n",
      "[-1  0 -1 -1 -1 -1 -1  0 -1  0 30 30  0 -1  0]\n"
     ]
    }
   ],
   "source": [
    "# Error Points for our Module\n",
    "import numpy as np\n",
    "l2Act = np.asarray(l2Act)\n",
    "months_pregnant_out = np.asarray(months_pregnant_out)\n",
    "indexing = l2Act!=months_pregnant_out\n",
    "errorPoints = monthsPregnant[indexing]['STT transcription'].to_numpy()\n",
    "print(len(errorPoints))\n",
    "print(errorPoints)\n",
    "print(l2Act[indexing])\n",
    "print(months_pregnant_out[indexing])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>#############################################################################</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(165, 7) (158, 7) (56, 7)\n"
     ]
    }
   ],
   "source": [
    "nc12 = pd.read_excel('noOfChildrenR12.xlsx')\n",
    "nc3 = pd.read_excel('noOfChildrenR3.xlsx')\n",
    "nc4 = pd.read_excel('noOfChildrenR4.xlsx')\n",
    "\n",
    "print(nc12.shape, nc3.shape, nc4.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(379, 7)\n"
     ]
    }
   ],
   "source": [
    "noOfChildren = pd.concat([nc12, nc3, nc4])\n",
    "print(noOfChildren.shape)\n",
    "# noOfChildren = noOfChildren[noOfChildren['Quality']==1]\n",
    "# print(noOfChildren.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {},
   "outputs": [],
   "source": [
    "noOfChildren_out = []\n",
    "for text in noOfChildren['STT transcription']:\n",
    "    text = str(text)\n",
    "    a, b = findNumeralData(text)\n",
    "    noOfChildren_out.append(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {},
   "outputs": [],
   "source": [
    "noOfChildren_gt = noOfChildren['Ground truth entity']\n",
    "noOfChildren_act = []\n",
    "\n",
    "for item in noOfChildren_gt:\n",
    "    try:\n",
    "        if (type(int(item)) == int):\n",
    "            noOfChildren_act.append(int(item))\n",
    "    except:\n",
    "            noOfChildren_act.append(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {},
   "outputs": [],
   "source": [
    "noOfChildDf = []\n",
    "import json\n",
    "# nc12 = nc12[nc12['Quality']==1]\n",
    "noOfChildren_df12 = nc12['DF entity'].tolist()\n",
    "for pred in noOfChildren_df12:\n",
    "        try:\n",
    "            ent = json.loads(pred)\n",
    "            noOfChildDf.append(str(list(ent['entity'][0].values())[0]))\n",
    "        except:\n",
    "            noOfChildDf.append(\"#\")\n",
    "            \n",
    "noOfChildren_dfOut = [-1 if item=='#' else int(item) for item in noOfChildDf]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nc3 = nc3[nc3['Quality']==1]\n",
    "# nc4 = nc4[nc4['Quality']==1]\n",
    "noOfChildren_df34 = pd.concat([nc3['DF entity'], nc4['DF entity']]).tolist()\n",
    "for item in noOfChildren_df34:\n",
    "    try:\n",
    "        if (type(int(item))==int):\n",
    "            noOfChildren_dfOut.append(int(item))\n",
    "    except:\n",
    "        noOfChildren_dfOut.append(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "379 379 379\n"
     ]
    }
   ],
   "source": [
    "print(len(noOfChildren_out), len(noOfChildren_act), len(noOfChildren_dfOut))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {},
   "outputs": [],
   "source": [
    "l1Act, l2Act = [], []\n",
    "for item in noOfChildren_gt:\n",
    "    try:\n",
    "        if (type(int(item)) == int):\n",
    "            l1Act.append(1)\n",
    "            l2Act.append(int(item))\n",
    "    except:\n",
    "            l1Act.append(0)\n",
    "            l2Act.append(-1)\n",
    "\n",
    "l1Out = []\n",
    "for item in noOfChildren_out:\n",
    "    if item==-1:\n",
    "        l1Out.append(0)\n",
    "    else:\n",
    "        l1Out.append(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {},
   "outputs": [],
   "source": [
    "l1Out = []\n",
    "for item in noOfChildren_dfOut:\n",
    "    if item==-1:\n",
    "        l1Out.append(0)\n",
    "    else:\n",
    "        l1Out.append(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9968354430379747\n",
      "0.9264705882352942\n",
      "0.8653846153846154\n",
      "Presence Identification accuracy is  0.8680738786279684\n",
      "Correctness accuracy is  0.8073878627968337\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, f1_score, recall_score, confusion_matrix\n",
    "print(precision_score(l1Act,l1Out))\n",
    "print(f1_score(l1Act,l1Out))\n",
    "print(recall_score(l1Act, l1Out))\n",
    "print(\"Presence Identification accuracy is \",accuracy_score(l1Act, l1Out))\n",
    "print(\"Correctness accuracy is \",accuracy_score(l2Act,noOfChildren_dfOut))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 14   1]\n",
      " [ 49 315]]\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(l1Act, l1Out))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>#####################################################################</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(204, 7) (224, 7) (98, 7)\n"
     ]
    }
   ],
   "source": [
    "# tf stands for total family\n",
    "# 967 - 748 Ignore it\n",
    "\n",
    "tf12 = pd.read_excel('totalFamilyR12.xlsx')\n",
    "tf3 = pd.read_excel('totalFamilyR3.xlsx')\n",
    "tf4 = pd.read_excel('totalFamilyR4.xlsx')\n",
    "\n",
    "print(tf12.shape, tf3.shape, tf4.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(526, 7)\n"
     ]
    }
   ],
   "source": [
    "totalFamily = pd.concat([tf12, tf3, tf4])\n",
    "print(totalFamily.shape)\n",
    "# totalFamily = totalFamily[totalFamily['Quality']==1]\n",
    "# print(totalFamily.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {},
   "outputs": [],
   "source": [
    "totalFamily_out = []\n",
    "for text in totalFamily['STT transcription']:\n",
    "    text = str(text)\n",
    "    a, b = findNumeralData(text)\n",
    "    totalFamily_out.append(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "metadata": {},
   "outputs": [],
   "source": [
    "totalFamily_gt = totalFamily['Ground truth entity']\n",
    "totalFamily_act = []\n",
    "\n",
    "for item in totalFamily_gt:\n",
    "    try:\n",
    "        if (type(int(item)) == int):\n",
    "            totalFamily_act.append(int(item))\n",
    "    except:\n",
    "            totalFamily_act.append(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "metadata": {},
   "outputs": [],
   "source": [
    "totalFamilyDF = []\n",
    "import json\n",
    "# tf12 = tf12[tf12['Quality']==1]\n",
    "totalFamily_df12 = tf12['DF entity'].tolist()\n",
    "for pred in totalFamily_df12:\n",
    "        try:\n",
    "            ent = json.loads(pred)\n",
    "            totalFamilyDF.append(str(list(ent['entity'][0].values())[0]))\n",
    "        except:\n",
    "            totalFamilyDF.append(\"#\")\n",
    "            \n",
    "totalFamily_dfOut = [-1 if item=='#' else int(item) for item in totalFamilyDF]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tf3 = tf3[tf3['Quality']==1]\n",
    "# tf4 = tf4[tf4['Quality']==1]\n",
    "totalFamily_df34 = pd.concat([tf3['DF entity'], tf4['DF entity']]).tolist()\n",
    "for item in totalFamily_df34:\n",
    "    try:\n",
    "        if (type(int(item))==int):\n",
    "            totalFamily_dfOut.append(int(item))\n",
    "    except:\n",
    "        totalFamily_dfOut.append(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "metadata": {},
   "outputs": [],
   "source": [
    "l1Act, l2Act = [], []\n",
    "for item in totalFamily_gt:\n",
    "    try:\n",
    "        if (type(int(item)) == int):\n",
    "            l1Act.append(1)\n",
    "            l2Act.append(int(item))\n",
    "    except:\n",
    "            l1Act.append(0)\n",
    "            l2Act.append(-1)\n",
    "\n",
    "l1Out = []\n",
    "for item in totalFamily_out:\n",
    "    if item==-1:\n",
    "        l1Out.append(0)\n",
    "    else:\n",
    "        l1Out.append(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "metadata": {},
   "outputs": [],
   "source": [
    "l1Out = []\n",
    "for item in totalFamily_dfOut:\n",
    "    if item==-1:\n",
    "        l1Out.append(0)\n",
    "    else:\n",
    "        l1Out.append(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9562043795620438\n",
      "0.8911564625850341\n",
      "0.8343949044585988\n",
      "Presence Identification accuracy is  0.8174904942965779\n",
      "Correctness accuracy is  0.7604562737642585\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, f1_score, recall_score, confusion_matrix\n",
    "print(precision_score(l1Act,l1Out))\n",
    "print(f1_score(l1Act,l1Out))\n",
    "print(recall_score(l1Act, l1Out))\n",
    "print(\"Presence Identification accuracy is \",accuracy_score(l1Act, l1Out))\n",
    "print(\"Correctness accuracy is \",accuracy_score(l2Act,totalFamily_out))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 37  18]\n",
      " [ 78 393]]\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(l1Act, l1Out))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Accuracy Combined</b> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [],
   "source": [
    "numberOut = months_pregnant_out + noOfChildren_out + totalFamily_out\n",
    "numberAct = months_pregnant_act + noOfChildren_act + totalFamily_act\n",
    "numberDF = months_pregnant_dfOut + noOfChildren_dfOut + totalFamily_dfOut"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "748 748 748\n"
     ]
    }
   ],
   "source": [
    "print(len(numberAct), len(numberOut), len(numberDF))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number Accuracy for our module is  0.9572192513368984\n",
      "Number Accuracy for Dialogflow is  0.9037433155080213\n"
     ]
    }
   ],
   "source": [
    "print(\"Number Accuracy for our module is \",accuracy_score(numberAct, numberOut))\n",
    "print(\"Number Accuracy for Dialogflow is \", accuracy_score(numberAct, numberDF))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Yes/No"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 402,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(249, 7) (206, 7) (108, 7)\n"
     ]
    }
   ],
   "source": [
    "yn12 = pd.read_excel('haaNaTrain.xlsx')\n",
    "yn3 = pd.read_excel('yesNoR3.xlsx')\n",
    "yn4 = pd.read_excel('yesNoR4.xlsx')\n",
    "\n",
    "print(yn12.shape, yn3.shape, yn4.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 403,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(563, 7)\n",
      "(504, 7)\n"
     ]
    }
   ],
   "source": [
    "haaNa = pd.concat([yn12, yn3, yn4])\n",
    "print(haaNa.shape)\n",
    "haaNa = haaNa[haaNa['Quality']==1]\n",
    "print(haaNa.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 404,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "This script takes the user query as input and computes a\n",
    "semantic search between the words in the Yes list and No\n",
    "list to return if the user wanted to say 'Yes' or 'No' to the\n",
    "question (or perhaps 'Maybe').\n",
    "Reference : https://github.com/UKPLab/sentence-transformers/blob/master/examples/applications/semantic_search.py\n",
    "\"\"\"\n",
    "import argparse\n",
    "import os\n",
    "import sys\n",
    "import torch\n",
    "\n",
    "from sentence_transformers import SentenceTransformer, util\n",
    "\n",
    "embedder = SentenceTransformer('distiluse-base-multilingual-cased')\n",
    "\n",
    "def get_edit_distance_score():\n",
    "    return\n",
    "\n",
    "def get_semantic_score(query):\n",
    "    \"\"\"\n",
    "        0 : No\n",
    "        1 : Yes\n",
    "        2 : Maybe\n",
    "    \"\"\"\n",
    "\n",
    "    mapping_codes = {\n",
    "        0:'No',\n",
    "        1:'Yes'\n",
    "    }\n",
    "\n",
    "    # Corpus with example sentences\n",
    "    corpus = {'हाँजी बिलकुल है': 1,\n",
    "              'हाँजी': 1,\n",
    "              'हाँ': 1,\n",
    "              'हाँ घर में गर्वभती महिला है': 1,\n",
    "              'नहीं': 0,\n",
    "              'बिलकुल नहीं': 0,\n",
    "              'नहीं घर में गर्वभती महिला नहीं है': 0,\n",
    "              }\n",
    "\n",
    "    corpus_questions = list(corpus.keys())\n",
    "    corpus_embeddings = embedder.encode(corpus_questions, convert_to_tensor=True)\n",
    "\n",
    "    # Find the closest 1 sentences of the corpus for query sentence based on cosine similarity\n",
    "    top_k = 1       # NOTE: Provide as a command line argument\n",
    "    query_embedding = embedder.encode(query, convert_to_tensor=True)\n",
    "    cos_scores = util.pytorch_cos_sim(query_embedding, corpus_embeddings)[0]\n",
    "    cos_scores = cos_scores.cpu()\n",
    "\n",
    "    # Use torch.topk to find the highest 5 scores\n",
    "    top_results = torch.topk(cos_scores, k=top_k)\n",
    "\n",
    "#     print(\"\\n\\n======================\\n\\n\")\n",
    "#     print(\"Query:\", query)\n",
    "    # print(\"\\nTop most similar sentences in corpus:\")\n",
    "\n",
    "    # for score, idx in zip(top_results[0], top_results[1]):\n",
    "    #     print(corpus_questions[idx], \"(Score: %.4f)\" % (score))\n",
    "    \n",
    "#     print(top_results)\n",
    "#     return top_results\n",
    "#     print(\"Final Answer : {}\".format(mapping_codes[corpus[corpus_questions[top_results[1]]]]))\n",
    "#     return mapping_codes[corpus[corpus_questions[top_results[1]]]]\n",
    "    \n",
    "#     print(\"****************************************************************************\")\n",
    "#     print(mapping_codes[corpus[corpus_questions[top_results[1]]]])\n",
    "#     print(\"############################################################################\")\n",
    "    out = str(mapping_codes[corpus[corpus_questions[top_results[1]]]])\n",
    "#     print(out)\n",
    "    return out\n",
    "\n",
    "def bert_yes_no(query):\n",
    "    semantic_score = get_semantic_score(query)\n",
    "    return semantic_score\n",
    "#     print(\"Semantic score : {}\".format(semantic_score))\n",
    "    # edit_distance_score = get_edit_distance_score()\n",
    "\n",
    "    # avg_score = (semantic_score+edit_distance_score)/2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 405,
   "metadata": {},
   "outputs": [],
   "source": [
    "yesNoQues = haaNa['STT transcription']\n",
    "yesNoValue = haaNa['Ground truth entity']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 406,
   "metadata": {},
   "outputs": [],
   "source": [
    "bertQ1Out = [bert_yes_no(text) for text in yesNoQues]\n",
    "yesNoOut = [1 if item=='Yes' else 0 for item in bertQ1Out]\n",
    "# print(bertQ1Out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 407,
   "metadata": {},
   "outputs": [],
   "source": [
    "yesNoAct = []\n",
    "for text in yesNoValue:\n",
    "    if text=='Yes' or text=='yes' or text=='yes ' or text=='Yes ' or text==' Yes' or text==' yes':\n",
    "        yesNoAct.append(1)\n",
    "    elif text=='No' or text=='no' or text=='No ' or text=='no ' or text==' No' or text==' no':\n",
    "        yesNoAct.append(0)\n",
    "    else:\n",
    "        yesNoAct.append(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 408,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9920634920634921\n"
     ]
    }
   ],
   "source": [
    "print(accuracy_score(yesNoAct, yesNoOut))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 388,
   "metadata": {},
   "outputs": [],
   "source": [
    "l1YesNoAct, l1YesNoOut = [], []\n",
    "\n",
    "for text in yesNoAct:\n",
    "        if text==1 or text==0:\n",
    "            l1YesNoAct.append(1)\n",
    "        else:\n",
    "            l1YesNoAct.append(0)\n",
    "\n",
    "for text in yesNoOut:\n",
    "    if text==1 or text==0:\n",
    "        l1YesNoOut.append(1)\n",
    "    else:\n",
    "        l1YesNoOut.append(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 389,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  0  24]\n",
      " [  0 539]]\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(l1YesNoAct, l1YesNoOut))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 390,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9573712255772646\n",
      "0.9782214156079855\n",
      "1.0\n",
      "0.9573712255772646\n"
     ]
    }
   ],
   "source": [
    "print(precision_score(l1YesNoAct,l1YesNoOut))\n",
    "print(f1_score(l1YesNoAct, l1YesNoOut))\n",
    "print(recall_score(l1YesNoAct, l1YesNoOut))\n",
    "print(accuracy_score(l1YesNoAct, l1YesNoOut))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 391,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  0   6  18]\n",
      " [  0 446  20]\n",
      " [  0   2  71]]\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(yesNoAct, yesNoOut))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Dialogflow for yes/no</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 409,
   "metadata": {},
   "outputs": [],
   "source": [
    "yn12 = yn12[yn12['Quality']==1]\n",
    "q1DF = yn12['DF entity']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 410,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "q1Pred = []\n",
    "for pred in q1DF:\n",
    "        try:\n",
    "            ent = json.loads(pred)\n",
    "            q1Pred.append(str(list(ent['entity'][0].values())[0]))\n",
    "        except:\n",
    "            q1Pred.append(str(-1))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 411,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, -1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, -1, 0, -1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, -1, 0, 1, 0, 0, 0, 0, 1, 1, 0, -1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, -1, 0, 1, 0, 1, 0, 1, 0, -1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, -1, 0, 0, 0, -1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, -1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, -1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, -1, 0, -1, -1, 0, 0, 0, 0, 0]\n"
     ]
    }
   ],
   "source": [
    "yesNoDFOut = [1 if item=='yes' else 0 if item=='no' else -1 for item in q1Pred]\n",
    "print(yesNoDFOut)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 412,
   "metadata": {},
   "outputs": [],
   "source": [
    "yn3 = yn3[yn3['Quality']==1]\n",
    "yn4 = yn4[yn4['Quality']==1]\n",
    "yesNo_df34 = pd.concat([yn3['DF entity'], yn4['DF entity']]).tolist()\n",
    "for text in yesNo_df34:\n",
    "    text = str(text)\n",
    "    if text=='Yes' or text=='yes' or text=='yes ' or text=='Yes ' or text==' Yes' or text==' yes':\n",
    "        yesNoDFOut.append(1)\n",
    "    elif text=='No' or text=='no' or text=='No ' or text=='no ' or text==' No' or text==' no':\n",
    "        yesNoDFOut.append(0)\n",
    "    else:\n",
    "        yesNoDFOut.append(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 413,
   "metadata": {},
   "outputs": [],
   "source": [
    "l1YesNoAct, l1YesNoDFOut = [], []\n",
    "\n",
    "for text in yesNoAct:\n",
    "        if text==1 or text==0:\n",
    "            l1YesNoAct.append(1)\n",
    "        else:\n",
    "            l1YesNoAct.append(0)\n",
    "\n",
    "for text in yesNoDFOut:\n",
    "    if text==1 or text==0:\n",
    "        l1YesNoDFOut.append(1)\n",
    "    else:\n",
    "        l1YesNoDFOut.append(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 418,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9424603174603174\n"
     ]
    }
   ],
   "source": [
    "print(accuracy_score(yesNoAct, yesNoDFOut))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 415,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  2   2]\n",
      " [ 18 482]]\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(l1YesNoAct, l1YesNoDFOut))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 416,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  2   0   2]\n",
      " [ 13 415   7]\n",
      " [  5   2  58]]\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(yesNoAct, yesNoDFOut))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 417,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9958677685950413\n",
      "0.9796747967479674\n",
      "0.964\n",
      "0.9603174603174603\n"
     ]
    }
   ],
   "source": [
    "print(precision_score(l1YesNoAct,l1YesNoDFOut))\n",
    "print(f1_score(l1YesNoAct, l1YesNoDFOut))\n",
    "print(recall_score(l1YesNoAct, l1YesNoDFOut))\n",
    "print(accuracy_score(l1YesNoAct, l1YesNoDFOut))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Age"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "umra12 = pd.read_excel('ageR12.xlsx')\n",
    "umra3 = pd.read_excel('ageR3.xlsx')\n",
    "umra4 = pd.read_excel('ageR4.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(119, 7) (143, 7) (39, 7)\n"
     ]
    }
   ],
   "source": [
    "print(umra12.shape, umra3.shape, umra4.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(301, 7)\n",
      "(240, 7)\n"
     ]
    }
   ],
   "source": [
    "age = pd.concat([umra12, umra3, umra4])\n",
    "print(age.shape)\n",
    "age = age[age['Quality']==1]\n",
    "print(age.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "import textdistance as td\n",
    "\n",
    "thresh = 0.80\n",
    "\n",
    "def preprocess_date(sent):\n",
    "    hi_nums = ['शून्य','एक','दो','तीन','चार','पांच','छः','सात','आठ','नौ','दस','ग्यारह','बारह','तेरह','चौदह',\n",
    "             'पंद्रह','सोलह','सत्रह','अट्ठारह','उन्निस','बीस','इक्कीस','बाईस','तेईस','चौबीस','पच्चीस','छब्बीस','सत्ताईस','अट्ठाईस','उनतीस','तीस','इकतीस',\n",
    "             'बत्तीस','तैंतीस','चौंतीस','पैंतीस','छ्त्तीस','सैंतीस','अड़तीस','उनतालीस','चालीस','इकतालीस','बयालीस','तैंतालीस','चौंतालीस',\n",
    "             'पैंतालीस','छियालीस','सैंतालीस','अड़तालीस','उनचास','पचास','इक्याबन','बावन','तिरेपन','चौबन','पचपन','छप्पन','सत्तावन',\n",
    "            'अट्ठावन','उनसठ','साठ','इकसठ','बासठ','तिरसठ','चौंसठ','पैंसठ','छियासठ','सड़सठ','अड़सठ','उनहत्तर','सत्तर','इकहत्तर',\n",
    "            'बहत्तर','तिहत्तर','चौहत्तर','पचहत्तर','छिहत्तर','सतहत्तर','अठहत्तर','उनासी','अस्सी','इक्यासी','बयासी','तिरासी','चौरासी',\n",
    "             'पचासी','छियासी','सतासी','अठासी' ,'नवासी','नब्बे','इक्यानबे','बानवे','तिरानवे','चौरानवे','पचानवे','छियानवे','सत्तानवे',\n",
    "             'अट्ठानवे','निन्यानवे' ,'सौ']\n",
    "    \n",
    "    pos_words = {'डेढ़':'1 साल 6 महीना', 'ढाई':'2 साल 6 महीना','डाइट':'2 साल 6 महीना', 'चार्ट':'साल', 'वर्स':'साल',\n",
    "                 'वर्ष':'साल', 'नव':'9','नाना':'9', 'चैप्टर':'4', 'वाट':'साल'}\n",
    "    \n",
    "    sent = str(sent)\n",
    "    words = sent.split(' ')\n",
    "    out_sent = []\n",
    "    for idx, word in enumerate(words):    \n",
    "        for pw_idx, pos_word in enumerate(hi_nums):\n",
    "            if td.levenshtein.normalized_similarity(pos_word, word) >= thresh:\n",
    "                words[idx] = str(pw_idx)\n",
    "        for pos_word in pos_words:\n",
    "            if td.levenshtein.normalized_similarity(pos_word, word) >= thresh:\n",
    "                words[idx] = pos_words[pos_word]\n",
    "    \n",
    "    words = ' '.join(words)\n",
    "#     print(words)\n",
    "    return words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final logic of date extraction\n",
    "import re\n",
    "import datetime\n",
    "from dateparser.search import search_dates\n",
    "from dateutil.relativedelta import relativedelta\n",
    "\n",
    "out_dates = []    # This is the DoB\n",
    "ages = []\n",
    "curr_date = datetime.datetime.now()\n",
    "\n",
    "for sent in age['STT transcription']:\n",
    "    sent = preprocess_date(sent)\n",
    "    out = search_dates(sent)\n",
    "    if out == None and re.search('\\d+', sent) != None:\n",
    "        idx = re.search('\\d+', sent).end()\n",
    "        out = search_dates(sent[:idx]+' साल'+sent[idx:])\n",
    "    out_date = []\n",
    "    ageTemp = []\n",
    "    if out != None:\n",
    "        for o in out:\n",
    "            out_date.append(str(o[1].year) + ' years ' + str(o[1].month) + ' months ' + str(o[1].day) + ' days')\n",
    "            age_diff = relativedelta(curr_date.date(),o[1].date())\n",
    "            ageTemp.append(str(age_diff.years) + ' years ' + str(age_diff.months) + ' months ' + str(age_diff.days) + ' days ')\n",
    "    out_dates.append(','.join(out_date))\n",
    "    ages.append(','.join(ageTemp))\n",
    "# print(out_dates)\n",
    "# print(ages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "ageOutDin, ageOutMahina, ageOutSaal = [], [], []\n",
    "times = 0\n",
    "for sentence in ages:\n",
    "#     print(sentence)\n",
    "    items = sentence.split()\n",
    "    if len(items) > 0:\n",
    "        yInd = items.index('years')\n",
    "        dInd = items.index('days')\n",
    "        mInd = items.index('months')\n",
    "        ageOutDin.append(int(items[dInd-1]))\n",
    "        ageOutMahina.append(int(items[mInd-1]))\n",
    "        ageOutSaal.append(int(items[yInd-1]))\n",
    "    else:\n",
    "        times += 1\n",
    "        ageOutDin.append(-1)\n",
    "        ageOutMahina.append(-1)\n",
    "        ageOutSaal.append(-1)\n",
    "\n",
    "# print(ageOutDin)\n",
    "# print(ageOutMahina)\n",
    "# print(ageOutSaal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12\n"
     ]
    }
   ],
   "source": [
    "print(times)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # text = 21/01/01\n",
    "# text = '<noinfo>'\n",
    "# from datetime import datetime\n",
    "# try:\n",
    "#     curr_date = datetime.now()\n",
    "#     tempDate = datetime.strptime(text, '%d/%m/%y')\n",
    "#     print(tempDate)\n",
    "#     age_diff = relativedelta(curr_date.date(),tempDate.date())\n",
    "#     print(str(age_diff.years) + ' years ' + str(age_diff.months) + ' months ' + str(age_diff.days) + ' days ')\n",
    "# except:\n",
    "#     print(\"Kuch bhi nahi hua hai\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preferable date format for age data is dd/mm/yy \n",
    "ageGT = age['Ground truth entity'].to_numpy()\n",
    "from datetime import datetime\n",
    "ageActDin , ageActMahina, ageActSaal = [], [], []\n",
    "for sentence in ageGT:\n",
    "    sentence = str(sentence)\n",
    "    try:\n",
    "        curr_date = datetime.now()\n",
    "        tempDate = datetime.strptime(text, '%d/%m/%y')\n",
    "#         print(tempDate)\n",
    "        age_diff = relativedelta(curr_date.date(),tempDate.date())\n",
    "        ageActDin.append(age_diff.days)\n",
    "        ageActMahina.append(age_diff.months)\n",
    "        ageActSaal.append(age_diff.years)\n",
    "        print(str(age_diff.years) + ' years ' + str(age_diff.months) + ' months ' + str(age_diff.days) + ' days ')\n",
    "    except:\n",
    "        sentence = sentence.replace(\",\",\" \")\n",
    "        items = sentence.split()\n",
    "    \n",
    "        if len(items)==1:\n",
    "            ageActSaal.append(-1)\n",
    "            ageActMahina.append(-1)\n",
    "            ageActDin.append(-1)\n",
    "            continue\n",
    "\n",
    "        if \"years\" in items:\n",
    "    #         print(\"aaya kay\")\n",
    "            inY = items.index(\"years\")\n",
    "            ageActSaal.append(int(items[inY-1]))\n",
    "        elif \"Years\" in items:\n",
    "            inY = items.index(\"Years\")\n",
    "            ageActSaal.append(int(items[inY-1]))\n",
    "        else:\n",
    "            ageActSaal.append(0)\n",
    "\n",
    "        if \"months\" in items:\n",
    "            inM = items.index(\"months\")\n",
    "            ageActMahina.append(int(items[inM-1]))\n",
    "        elif \"Months\" in items:\n",
    "            inM = items.index(\"Months\")\n",
    "            ageActMahina.append(int(items[inM-1]))\n",
    "        else:\n",
    "            ageActMahina.append(0)\n",
    "\n",
    "        if \"days\" in items:\n",
    "            inD = items.index(\"days\")\n",
    "            ageActDin.append(int(items[inD-1]))\n",
    "        elif \"Days\" in items:\n",
    "            inD = items.index(\"Days\")\n",
    "            ageActDin.append(int(items[inD-1]))\n",
    "        else:\n",
    "            ageActDin.append(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> Dialogflow for age </b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "umra12 = umra12[umra12['Quality']==1]\n",
    "umra12DF = umra12['DF entity']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "umra12DFPred = []\n",
    "for pred in umra12DF:\n",
    "        try:\n",
    "            ent = json.loads(pred)\n",
    "            umra12DFPred.append(str(list(ent['entity'][0].values())[0]))\n",
    "        except:\n",
    "            umra12DFPred.append('NOENTITY')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "umra3 = umra3[umra3['Quality']==1]\n",
    "umra4 = umra4[umra4['Quality']==1]\n",
    "umra_df34 = pd.concat([umra3['DF entity'], umra4['DF entity']]).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "ageDF = umra12DFPred + umra_df34"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "49\n",
      "50\n",
      "51\n",
      "52\n",
      "53\n",
      "54\n",
      "55\n",
      "56\n",
      "57\n",
      "58\n",
      "59\n",
      "60\n",
      "61\n",
      "62\n",
      "63\n",
      "64\n",
      "65\n",
      "66\n",
      "67\n",
      "68\n",
      "69\n",
      "70\n",
      "71\n",
      "72\n",
      "73\n",
      "74\n",
      "75\n",
      "76\n",
      "77\n",
      "78\n",
      "79\n",
      "80\n",
      "81\n",
      "82\n",
      "83\n",
      "84\n",
      "85\n",
      "86\n",
      "87\n",
      "88\n",
      "89\n",
      "90\n",
      "91\n",
      "92\n",
      "93\n",
      "94\n",
      "95\n",
      "96\n",
      "97\n",
      "98\n",
      "99\n",
      "100\n",
      "101\n",
      "102\n",
      "103\n",
      "104\n",
      "105\n",
      "106\n",
      "107\n",
      "108\n",
      "109\n",
      "110\n",
      "111\n",
      "112\n",
      "113\n",
      "114\n",
      "115\n",
      "116\n",
      "117\n",
      "118\n",
      "119\n",
      "120\n",
      "121\n",
      "122\n",
      "123\n",
      "124\n",
      "125\n",
      "126\n",
      "127\n",
      "128\n",
      "129\n",
      "130\n",
      "131\n",
      "132\n",
      "133\n",
      "134\n",
      "135\n",
      "136\n",
      "137\n",
      "138\n",
      "139\n",
      "140\n",
      "141\n",
      "142\n",
      "143\n",
      "144\n",
      "145\n",
      "146\n",
      "147\n",
      "148\n",
      "149\n",
      "150\n",
      "151\n",
      "152\n",
      "153\n",
      "154\n",
      "155\n",
      "156\n",
      "157\n",
      "158\n",
      "159\n",
      "160\n",
      "161\n",
      "162\n",
      "163\n",
      "164\n",
      "165\n",
      "166\n",
      "167\n",
      "168\n",
      "169\n",
      "170\n",
      "171\n",
      "172\n",
      "173\n",
      "174\n",
      "175\n",
      "176\n",
      "177\n",
      "178\n",
      "179\n",
      "180\n",
      "181\n",
      "182\n",
      "183\n",
      "184\n",
      "185\n",
      "186\n",
      "187\n",
      "188\n",
      "189\n",
      "190\n",
      "191\n",
      "192\n",
      "193\n",
      "194\n",
      "195\n",
      "196\n",
      "197\n",
      "198\n",
      "199\n",
      "200\n",
      "201\n",
      "202\n",
      "203\n",
      "204\n",
      "205\n",
      "206\n",
      "207\n",
      "208\n",
      "209\n",
      "210\n",
      "211\n",
      "212\n",
      "213\n",
      "214\n",
      "215\n",
      "216\n",
      "217\n",
      "218\n",
      "219\n",
      "220\n",
      "221\n",
      "222\n",
      "223\n",
      "224\n",
      "225\n",
      "226\n",
      "227\n",
      "228\n",
      "229\n",
      "230\n",
      "231\n",
      "232\n",
      "233\n",
      "234\n",
      "235\n",
      "236\n",
      "237\n",
      "238\n",
      "239\n"
     ]
    }
   ],
   "source": [
    "start = 0\n",
    "ageDFDin, ageDFMahina, ageDFSaal = [], [], []\n",
    "for sentence in ageDF:\n",
    "    print(start)\n",
    "    start += 1\n",
    "    sentence = str(sentence)\n",
    "#     print(sentence)\n",
    "    sentence = sentence.replace(\",\",\" \")\n",
    "    items = sentence.split()\n",
    "    \n",
    "    if len(items)==1:\n",
    "        try:\n",
    "            if items[0]=='nan' or items[0]=='NOENTITY':\n",
    "                ageDFSaal.append(-1)\n",
    "                ageDFMahina.append(-1)\n",
    "                ageDFDin.append(-1)\n",
    "                continue\n",
    "            else :\n",
    "                ageDFSaal.append(int(items[0]))\n",
    "                ageDFMahina.append(0)\n",
    "                ageDFDin.append(0)\n",
    "            continue\n",
    "        except:\n",
    "            ageDFSaal.append(-1)\n",
    "            ageDFMahina.append(-1)\n",
    "            ageDFDin.append(-1)\n",
    "            continue\n",
    "        \n",
    "    if \"years\" in items:\n",
    "#         print(\"aaya kay\")\n",
    "        inY = items.index(\"years\")\n",
    "        ageDFSaal.append(int(items[inY-1]))\n",
    "    elif \"Years\" in items:\n",
    "        inY = items.index(\"Years\")\n",
    "        ageDFSaal.append(int(items[inY-1]))\n",
    "    elif \"Year\" in items:\n",
    "        inY = items.index(\"Year\")\n",
    "        ageDFSaal.append(int(items[inY-1]))\n",
    "    elif \"year\" in items:\n",
    "        inY = items.index(\"year\")\n",
    "        ageDFSaal.append(int(items[inY-1]))\n",
    "    else:\n",
    "        ageDFSaal.append(0)\n",
    "        \n",
    "    if \"months\" in items:\n",
    "        inM = items.index(\"months\")\n",
    "        ageDFMahina.append(int(items[inM-1]))\n",
    "    elif \"Months\" in items:\n",
    "        inM = items.index(\"Months\")\n",
    "        ageDFMahina.append(int(items[inM-1]))\n",
    "    elif \"Month\" in items:\n",
    "        inM = items.index(\"Month\")\n",
    "        ageDFMahina.append(int(items[inM-1]))\n",
    "    elif \"month\" in items:\n",
    "        inM = items.index(\"month\")\n",
    "        ageDFMahina.append(int(items[inM-1]))\n",
    "    else:\n",
    "        ageDFMahina.append(0)\n",
    "        \n",
    "    if \"days\" in items:\n",
    "        inD = items.index(\"days\")\n",
    "        ageDFDin.append(int(items[inD-1]))\n",
    "    elif \"Days\" in items:\n",
    "        inD = items.index(\"Days\")\n",
    "        ageDFDin.append(int(items[inD-1]))\n",
    "    elif \"Day\" in items:\n",
    "        inD = items.index(\"Day\")\n",
    "        ageDFDin.append(int(items[inD-1]))\n",
    "    elif \"day\" in items:\n",
    "        inD = items.index(\"day\")\n",
    "        ageDFDin.append(int(items[inD-1]))\n",
    "    else:\n",
    "        ageDFDin.append(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Din accuracy  0.725\n",
      "Mahina Accuarcy  0.7208333333333333\n",
      "Saal Accuracy  0.7125\n",
      "240\n"
     ]
    }
   ],
   "source": [
    "print(\"Din accuracy \",accuracy_score(ageActDin, ageDFDin))\n",
    "print(\"Mahina Accuarcy \",accuracy_score(ageActMahina, ageDFMahina))\n",
    "print(\"Saal Accuracy \", accuracy_score(ageActSaal, ageDFSaal))\n",
    "# print(len(ageActDin))\n",
    "print(len(ageOutDin))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[234   0]\n",
      " [  0   6]]\n",
      "[[139  61]\n",
      " [  0  40]]\n",
      "[[ 17  14]\n",
      " [  0 209]]\n"
     ]
    }
   ],
   "source": [
    "l1DinAct = [0 if item<=0 else 1 for item in ageActDin]\n",
    "l1MahinaAct = [0 if item==0 else 1 for item in ageActMahina]\n",
    "l1SaalAct = [0 if item==0 else 1 for item in ageActSaal]\n",
    "l1DOut = [0 if item<=0 else 1 for item in ageDFDin]\n",
    "l1MonthOut = [0 if item==0 else 1 for item in ageDFMahina]\n",
    "l1YearOut = [0 if item==0 else 1 for item in ageDFSaal]\n",
    "print(confusion_matrix(l1DinAct, l1DOut))\n",
    "print(confusion_matrix(l1MahinaAct, l1MonthOut))\n",
    "print(confusion_matrix(l1SaalAct, l1YearOut))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n"
     ]
    }
   ],
   "source": [
    "print(precision_score(l1DinAct,l1DOut))\n",
    "print(f1_score(l1DinAct, l1DOut))\n",
    "print(recall_score(l1DinAct, l1DOut))\n",
    "print(accuracy_score(l1DinAct, l1DOut))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.39603960396039606\n",
      "0.5673758865248227\n",
      "1.0\n",
      "0.7458333333333333\n"
     ]
    }
   ],
   "source": [
    "print(precision_score(l1MahinaAct,l1MonthOut))\n",
    "print(f1_score(l1MahinaAct, l1MonthOut))\n",
    "print(recall_score(l1MahinaAct, l1MonthOut))\n",
    "print(accuracy_score(l1MahinaAct, l1MonthOut))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9372197309417041\n",
      "0.9675925925925926\n",
      "1.0\n",
      "0.9416666666666667\n"
     ]
    }
   ],
   "source": [
    "print(precision_score(l1SaalAct,l1YearOut))\n",
    "print(f1_score(l1SaalAct, l1YearOut))\n",
    "print(recall_score(l1SaalAct, l1YearOut))\n",
    "print(accuracy_score(l1SaalAct, l1YearOut))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
