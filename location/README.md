# Location and Category Classifier
This repository contains the code to automate the location and category tagging for moderators which will be useful for the MMI requirements.

## Process description

The module does two things : Infer location and infer the item category.

## When is the speech2text transcript generated

The speech2text transcript is generated when:
- The moderator marked transcript is not present.
- The Words Per Second from the moderatore marked transcript < 0.75.
- The location inferred from the moderator marked transcript is precise only to the state level and does not contain district or subdistrict.

### Location Inference

The location is initially obtained through 3 sources:

- Moderator marked locations present in the database.
- Location module inferred location from the moderator marked transcript.
- Location module inferred location from the automatically generated speech2text transcript.

The best inference is extracted from these three based on the following criteria:

- If there is a clash between the location provided by the moderator and those generated by the location module, rely on the moderator's marking.
- If the states match between the moderator marked location and the module generated location then take whichever is more precise.

#### Example

Moderator transcript :

उत्तर-प्रदेश राज्य के हरदोई जिले से राजेश कुमार गौतम ने मोबाईल वाणी माध्यम से बताया कि इन्हे राशन नही मिल पा रहा है इस वजह से इन्हें समस्या हो रही है। मनरेगा के तहत जो एक हज़ार की राशि देने को कहा गया था,वो भी नही मिल रहा है 

Moderator Location : Empty

Inferred Location : Ghazipur, Uttar Pradesh

The speech2text API was not needed in this case because the WPS for the moderatoe generated transcript was already very good.


### Category Classification

The category classification is the task of identifying if the item belongs to one of the following categories :

- Out of Food
- Migrant stuck in city
- Gas relief not received
- Cash relief not received
- Agricultural livelihood issue
- Isolation center facilities issue
- Health emergency unmet
- Bank not accessible
- Social distancing not being followed
- Black marketing and price rise.

These are different from item tags marked by the moderators.

For all the items which have either the sos or the impact tag, the category classification algorithm is run which is mostly a keyword based algorithm for example the keyword list for the identification of an item belonging to the gas relief not received category is : 

gas_words = ['गैस', 'उज्ज्वला', 'योजना', 'योजनाओ', 'आयोजना', 'लाभ', 'सिलिंडर', ]

### Running instructions

In order to run the entire pipline just run : 

```python
python main.py --input_filepath="" --output_dirpath=""
```

The other command line arguments have a default value and the code should be able to run if the environment has been correctly set up.

The location inference is using <code>get_location.py</code>

The category inference is using <code>get_category.py</code>

generate_audio_files.py : Used to download all the required audios for speech2text

get_transcripts.py : To get the speech2text transcript

locationEntityMatch.py : Location module internal file, this is the main file where the entity extraction and then inference happens

main_loc.py : This is the main file for module location extraction and adds a lot of cleanups and preprocessing.

polyglot_location_analysis.py : Primary location extraction using polyglot.

utils.py : Utility functions have been defined here.

The other files are just for experiments.

- The pickle files have been created to store the location coordinates and the transliterated locations to limit the API calls.

- The census_hindi_sd.csv file must be in the same location as that of the main file inside that folder. (where sd is subdistrict)

Changes made to the location module
- Delhi modified from r.r.kshetra Delhi to Delhi (the initals might have been added for national capital)


### Following is not required anymore since main.py emulated entire pipeline.
In order to generate transcripts :
 - python generate_audio_files.py : downloading all the audio files from the excel links. It then converts them from mp3 to wav and from stereo to mono which is the preferred audio format for google's speech to text API.
 - python get_transcripts.py : to extract the transcripts and save them in form of text files.
 - If you just run get_transcripts.py even then it takes input of the audio link and then generates the required format but it will take more time.

After the automatic transcripts have been generated they get saved and are later used in main.py

In order to get all the inferences, we just need to run main.py

